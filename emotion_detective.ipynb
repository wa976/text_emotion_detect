{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["OTp1jmz_VIHL"],"machine_shape":"hm","toc_visible":true,"authorship_tag":"ABX9TyPvo2S5lyYgUUkV3uI0se4C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 필요 라이브러리 다운및 import"],"metadata":{"id":"KvfgIbpxUHAR"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"bICG7qFjXFMG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663909922364,"user_tz":-480,"elapsed":26016,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"528eed66-a357-42d9-b0da-b8f8c48756a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[K     |████████████████████████████████| 49.1 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.9)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595728 sha256=2b3e085b40dcba31703607aade2060f48624daec9278596d019b92c6da627913\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 6.5 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.64.1)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.97)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 56.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2022.6.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.21.6)\n","Collecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 72.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=adebc024158712f2bad4e90d50e499b2d15adc46016d0aebafef3752e81cbb8c\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.8.1rc1 transformers-3.0.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"]}],"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3.0.2\n","!pip install torch"]},{"cell_type":"code","source":["!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h5D6q1sLU5yp","executionInfo":{"status":"ok","timestamp":1663910029520,"user_tz":-480,"elapsed":107163,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"11a8ac3f-cde8-44e5-d7b4-6754ea9dea12"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-yadfbbtu\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-yadfbbtu\n","Collecting boto3<=1.15.18\n","  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n","\u001b[K     |████████████████████████████████| 129 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n","Collecting mxnet<=1.7.0.post2,>=1.4.0\n","  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n","\u001b[K     |████████████████████████████████| 54.7 MB 39 kB/s \n","\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n","  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[K     |████████████████████████████████| 4.5 MB 75.8 MB/s \n","\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 76.2 MB/s \n","\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n","  Downloading torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.1 MB/s eta 0:00:43tcmalloc: large alloc 1147494400 bytes == 0x3a788000 @  0x7f56b5d6c615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n","\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n","\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n","  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 59.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.17.3)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (2.0.7)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.19.0,>=1.18.18\n","  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n","\u001b[K     |████████████████████████████████| 6.7 MB 50.8 MB/s \n","\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n","  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n","\u001b[K     |████████████████████████████████| 73 kB 2.5 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.23.0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.6.15)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.53)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 64.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.12.0)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.1.0)\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15708 sha256=3c8492d881532d2bdded61f11ab6440155c962e1140f628bf845fb6bef6eb1a5\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kn35coc6/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n","Successfully built kobert\n","Installing collected packages: jmespath, botocore, tokenizers, s3transfer, huggingface-hub, transformers, torch, sentencepiece, onnxruntime, mxnet, boto3, kobert\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.8.1rc1\n","    Uninstalling tokenizers-0.8.1rc1:\n","      Successfully uninstalled tokenizers-0.8.1rc1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 3.0.2\n","    Uninstalling transformers-3.0.2:\n","      Successfully uninstalled transformers-3.0.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: sentencepiece\n","    Found existing installation: sentencepiece 0.1.97\n","    Uninstalling sentencepiece-0.1.97:\n","      Successfully uninstalled sentencepiece-0.1.97\n","  Attempting uninstall: mxnet\n","    Found existing installation: mxnet 1.9.1\n","    Uninstalling mxnet-1.9.1:\n","      Successfully uninstalled mxnet-1.9.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.15.18 botocore-1.18.18 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1\n"]}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook"],"metadata":{"id":"kgriUaDzU5wR","executionInfo":{"status":"ok","timestamp":1663910032407,"user_tz":-480,"elapsed":2891,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from kobert import get_tokenizer\n","from kobert import get_pytorch_kobert_model\n","\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"],"metadata":{"id":"yqPYO4v_U5t1","executionInfo":{"status":"ok","timestamp":1663910034935,"user_tz":-480,"elapsed":2533,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["bertmodel, vocab = get_pytorch_kobert_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ag8rxjQLU5rm","executionInfo":{"status":"ok","timestamp":1663910047659,"user_tz":-480,"elapsed":12727,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"c6a45256-e20c-4127-da9b-25ab10e00b35"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n","/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9viOeZyV6wV","executionInfo":{"status":"ok","timestamp":1663910071701,"user_tz":-480,"elapsed":24055,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"6a079e85-e81d-4743-bc2f-6fea8978e96f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# 데이터 전처리"],"metadata":{"id":"PcZG2f1xUNd8"}},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/kmong/emotion_detect/data/text_data.csv',encoding='cp949')"],"metadata":{"id":"10oCNY7EU5pR","executionInfo":{"status":"ok","timestamp":1663910072802,"user_tz":-480,"elapsed":1106,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUxdaPb6U5m9","executionInfo":{"status":"ok","timestamp":1663910072803,"user_tz":-480,"elapsed":27,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"3e4c95de-9e74-4bf2-b4ae-17a6209b2784"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["34453"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["df['emotion'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zoRqisZMLabS","executionInfo":{"status":"ok","timestamp":1663910072803,"user_tz":-480,"elapsed":25,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"60642ad5-85cd-4f33-e69f-28b874a1cade"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df['emotion'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d6I960GLlxP","executionInfo":{"status":"ok","timestamp":1663910072803,"user_tz":-480,"elapsed":23,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"8fe9baa9-d90a-4c85-e23c-b992f6b5a0b5"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4    8325\n","0    6872\n","6    4950\n","3    4057\n","1    3958\n","2    3367\n","5    2924\n","Name: emotion, dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["index = df[df['emotion']==6].index"],"metadata":{"id":"XOiLg_gz4FT_","executionInfo":{"status":"ok","timestamp":1663910072804,"user_tz":-480,"elapsed":22,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["print(index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUTvYRH65z7f","executionInfo":{"status":"ok","timestamp":1663910072804,"user_tz":-480,"elapsed":22,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"3c91673c-05bc-4b4b-cdf2-3c43101a5e46"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Int64Index([29503, 29504, 29505, 29506, 29507, 29508, 29509, 29510, 29511,\n","            29512,\n","            ...\n","            34443, 34444, 34445, 34446, 34447, 34448, 34449, 34450, 34451,\n","            34452],\n","           dtype='int64', length=4950)\n"]}]},{"cell_type":"code","source":["df = df.drop(index)"],"metadata":{"id":"s4rkYngu4j4H","executionInfo":{"status":"ok","timestamp":1663910072804,"user_tz":-480,"elapsed":20,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["df['emotion'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydUMFHY64kTU","executionInfo":{"status":"ok","timestamp":1663910072805,"user_tz":-480,"elapsed":20,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"4bc52a10-d2fb-441f-9b87-bc4211ad8fa2"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4    8325\n","0    6872\n","3    4057\n","1    3958\n","2    3367\n","5    2924\n","Name: emotion, dtype: int64"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["df.sample(n=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"vb0Nv0kZU5ky","executionInfo":{"status":"ok","timestamp":1663910072805,"user_tz":-480,"elapsed":17,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"7c5fd7ee-b536-4d80-bffd-cb33214ad58c"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  dialog  emotion\n","15474       다음 달이 출산일인데 담당 선생님이 나는 아기 잘 낳을 수 있을 거라고 하셨어.        3\n","12422          아빠가 가끔 어려운 이야기를 하실 때 이해 안 될 때가 있어서 혼란스러워.        2\n","20108                        남자친구랑 연애하고 있는데도 외로운 느낌이 들어.        4\n","28059                                 어제 너무 부끄러운 일이 있었어.        5\n","29158  친구들이 나한테 청첩장을 달라고 하는데, 난 친구들에게 내 결혼식을 알리고 싶지 않거든.        5\n","21877      선생님께 도움을 요청했더니 자신을 믿으라고 말씀하셨어. 품에 안겨서 펑펑 울었어.        4\n","3422                            시험 보는데 갑자기 배가 아파 와서 짜증나.        0\n","3024                    부모님이 나랑 언니랑 차별해. 나 너무 힘들고 짜증이 나.        0\n","17821  차, 착각하지 마! 내년 내내 오빠랑 같이 있는단 얘긴 같은 고등학교에 다니게 된다...        3\n","20314                   내 진로에 대해 생각해보고 싶은데 자꾸 성적이 앞길을 막아        4"],"text/html":["\n","  <div id=\"df-65b14b0f-ccd7-4484-8be9-71fc56faa636\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dialog</th>\n","      <th>emotion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>15474</th>\n","      <td>다음 달이 출산일인데 담당 선생님이 나는 아기 잘 낳을 수 있을 거라고 하셨어.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>12422</th>\n","      <td>아빠가 가끔 어려운 이야기를 하실 때 이해 안 될 때가 있어서 혼란스러워.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>20108</th>\n","      <td>남자친구랑 연애하고 있는데도 외로운 느낌이 들어.</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>28059</th>\n","      <td>어제 너무 부끄러운 일이 있었어.</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>29158</th>\n","      <td>친구들이 나한테 청첩장을 달라고 하는데, 난 친구들에게 내 결혼식을 알리고 싶지 않거든.</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>21877</th>\n","      <td>선생님께 도움을 요청했더니 자신을 믿으라고 말씀하셨어. 품에 안겨서 펑펑 울었어.</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3422</th>\n","      <td>시험 보는데 갑자기 배가 아파 와서 짜증나.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3024</th>\n","      <td>부모님이 나랑 언니랑 차별해. 나 너무 힘들고 짜증이 나.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17821</th>\n","      <td>차, 착각하지 마! 내년 내내 오빠랑 같이 있는단 얘긴 같은 고등학교에 다니게 된다...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>20314</th>\n","      <td>내 진로에 대해 생각해보고 싶은데 자꾸 성적이 앞길을 막아</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65b14b0f-ccd7-4484-8be9-71fc56faa636')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-65b14b0f-ccd7-4484-8be9-71fc56faa636 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-65b14b0f-ccd7-4484-8be9-71fc56faa636');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["data_list = []\n","for q,label in zip(df['dialog'], df['emotion']) :\n","  data = []\n","  data.append(q)\n","  data.append(str(label))\n","\n","  data_list.append(data)\n","\n","  "],"metadata":{"id":"ZENxyQ1oU5iX","executionInfo":{"status":"ok","timestamp":1663910072806,"user_tz":-480,"elapsed":17,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["print(data_list[0])\n","print(data_list[1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfp_26Rpd2bI","executionInfo":{"status":"ok","timestamp":1663910072806,"user_tz":-480,"elapsed":16,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"2d412ae3-11a7-4c06-c6d6-7bf1357af31d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[' 그건 그 여자 사정이지!', '0']\n","['나는  정말 이렇게 먹고는 못살아', '0']\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","dataset_train, dataset_test = train_test_split(data_list, test_size = 0.25, random_state =0)"],"metadata":{"id":"ALYztRKAd2Yb","executionInfo":{"status":"ok","timestamp":1663910072807,"user_tz":-480,"elapsed":15,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["print(len(dataset_train))\n","print(len(dataset_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ad48r4nRd2WP","executionInfo":{"status":"ok","timestamp":1663910072807,"user_tz":-480,"elapsed":15,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"debbcddb-5d3d-49a5-8059-ae3039369397"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["22127\n","7376\n"]}]},{"cell_type":"markdown","source":["# BERT DATASET"],"metadata":{"id":"4emMm8ajUY5S"}},{"cell_type":"code","source":["class BERTDataset(Dataset):\n","  def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n","    transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","    self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","    self.labels = [np.int32(i[label_idx])for i in dataset]\n","\n","  def __getitem__(self, i):\n","    return (self.sentences[i] + (self.labels[i],))\n","\n","  def __len__(self):\n","    return(len(self.labels))"],"metadata":{"id":"9D1X2yhqd2T5","executionInfo":{"status":"ok","timestamp":1663910072808,"user_tz":-480,"elapsed":14,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["parameter"],"metadata":{"id":"Bf3XF0dJUpMB"}},{"cell_type":"code","source":["max_len = 64\n","batch_size = 128\n","warmup_ratio = 0.1\n","num_epochs = 3\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate = 5e-5\n"],"metadata":{"id":"cz9lK1Asd2Ry","executionInfo":{"status":"ok","timestamp":1663910072808,"user_tz":-480,"elapsed":14,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["토큰화 과정"],"metadata":{"id":"q7_7ymgcUufr"}},{"cell_type":"code","source":["tokenizer = get_tokenizer()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APB0cDrvd2Pr","executionInfo":{"status":"ok","timestamp":1663910073331,"user_tz":-480,"elapsed":536,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"5e7c6cfa-473c-4b43-b03e-c42156e85d5c"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}]},{"cell_type":"code","source":["tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"metadata":{"id":"wKMcXfJSd2NW","executionInfo":{"status":"ok","timestamp":1663910073331,"user_tz":-480,"elapsed":3,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n","data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"],"metadata":{"id":"apTZ35lJU5gK","executionInfo":{"status":"ok","timestamp":1663910075231,"user_tz":-480,"elapsed":1902,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["data_train[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-j2dxoQgI1C","executionInfo":{"status":"ok","timestamp":1663910075232,"user_tz":-480,"elapsed":13,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"a1ec6038-3ee6-428c-d6d2-cde857e7a636"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([   2,  517, 6248, 2829, 6844,  633,  806, 3466,  633,  517,    5,\n","         517,    5,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1], dtype=int32),\n"," array(14, dtype=int32),\n"," array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       dtype=int32),\n"," 1)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xp42zdj0gIyn","executionInfo":{"status":"ok","timestamp":1663910075232,"user_tz":-480,"elapsed":11,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"0c1d7512-6223-4e70-f3e7-28d99466c4f0"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"markdown","source":["# BERT MODEL"],"metadata":{"id":"njQmY1HDU1Kp"}},{"cell_type":"code","source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=6,\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        else:\n","            out = pooler\n","        return self.classifier(out)"],"metadata":{"id":"-bmWTdNYgIwi","executionInfo":{"status":"ok","timestamp":1663910075233,"user_tz":-480,"elapsed":10,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["model = BERTClassifier(bertmodel,  dr_rate=0.5)"],"metadata":{"id":"I2V7YN-WhDSD","executionInfo":{"status":"ok","timestamp":1663910075233,"user_tz":-480,"elapsed":9,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Prepare optimizer and schedule (linear warmup and decay)\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]"],"metadata":{"id":"Y02YFk9ohDN4","executionInfo":{"status":"ok","timestamp":1663910075234,"user_tz":-480,"elapsed":10,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"hyt0fu2GhmHD","executionInfo":{"status":"ok","timestamp":1663910075234,"user_tz":-480,"elapsed":10,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)"],"metadata":{"id":"_urO2RRuhmE0","executionInfo":{"status":"ok","timestamp":1663910075234,"user_tz":-480,"elapsed":9,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"],"metadata":{"id":"JROrwnyphmCR","executionInfo":{"status":"ok","timestamp":1663910075235,"user_tz":-480,"elapsed":10,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc"],"metadata":{"id":"DQzGeUh-hl_x","executionInfo":{"status":"ok","timestamp":1663910075235,"user_tz":-480,"elapsed":10,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["# Training & save model"],"metadata":{"id":"5cI92-NiVB6q"}},{"cell_type":"code","source":["for e in range(num_epochs):\n","    train_acc = 0.0\n","    test_acc = 0.0\n","    model.train()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n","        optimizer.zero_grad()\n","        token_ids = token_ids.long()\n","        segment_ids = segment_ids.long()\n","        valid_length= valid_length\n","        label = label.long()\n","        out = model(token_ids, valid_length, segment_ids)\n","        loss = loss_fn(out, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()  # Update learning rate schedule\n","        train_acc += calc_accuracy(out, label)\n","        if batch_id % log_interval == 0:\n","            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n","        token_ids = token_ids.long()\n","        segment_ids = segment_ids.long()\n","        label = label.long()\n","        out = model(token_ids, valid_length, segment_ids)\n","        test_acc += calc_accuracy(out, label)\n","    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xLSfSGmoh0tY","executionInfo":{"status":"ok","timestamp":1663938505646,"user_tz":-480,"elapsed":14285847,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"45e56f1d-822c-4db6-8bff-4c7039b3b4d7"},"execution_count":35,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["  1%|          | 1/173 [00:31<1:30:56, 31.73s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 1 batch id 1 loss 1.8208636045455933 train acc 0.1875\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 173/173 [1:25:50<00:00, 29.77s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 1 train acc 0.4967013617663907\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 58/58 [09:47<00:00, 10.12s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 1 test acc 0.6741648706896551\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  1%|          | 1/173 [00:37<1:47:39, 37.56s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 2 batch id 1 loss 0.8398520946502686 train acc 0.6796875\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 173/173 [1:25:17<00:00, 29.58s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 2 train acc 0.6964459492006457\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 58/58 [09:52<00:00, 10.22s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 2 test acc 0.6987068965517241\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  1%|          | 1/173 [00:37<1:47:37, 37.54s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 3 batch id 1 loss 0.6353992223739624 train acc 0.7578125\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 173/173 [1:24:19<00:00, 29.25s/it]"]},{"output_type":"stream","name":"stdout","text":["epoch 3 train acc 0.7588104723220329\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 58/58 [09:36<00:00,  9.95s/it]"]},{"output_type":"stream","name":"stdout","text":["epoch 3 test acc 0.6983297413793103\n"]},{"output_type":"stream","name":"stderr","text":["\n","  1%|          | 1/173 [00:36<1:46:01, 36.99s/it]"]},{"output_type":"stream","name":"stdout","text":["epoch 4 batch id 1 loss 0.5049590468406677 train acc 0.828125\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 173/173 [1:24:38<00:00, 29.36s/it]"]},{"output_type":"stream","name":"stdout","text":["epoch 4 train acc 0.8082314612300162\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 58/58 [09:46<00:00, 10.12s/it]"]},{"output_type":"stream","name":"stdout","text":["epoch 4 test acc 0.6987068965517241\n"]},{"output_type":"stream","name":"stderr","text":["\n","  1%|          | 1/173 [00:38<1:49:17, 38.12s/it]"]},{"output_type":"stream","name":"stdout","text":["epoch 5 batch id 1 loss 0.4355171024799347 train acc 0.8671875\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 173/173 [1:24:50<00:00, 29.43s/it]"]},{"output_type":"stream","name":"stdout","text":["epoch 5 train acc 0.8407109240743634\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 58/58 [09:44<00:00, 10.08s/it]"]},{"output_type":"stream","name":"stdout","text":["epoch 5 test acc 0.701697198275862\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/MyDrive/kmong/emotion_detect/model_1.h5')"],"metadata":{"id":"ECgGHbpf08ku","executionInfo":{"status":"ok","timestamp":1663938506769,"user_tz":-480,"elapsed":1124,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["# Load Model & Predict"],"metadata":{"id":"OTp1jmz_VIHL"}},{"cell_type":"code","source":["model = BERTClassifier(bertmodel,  dr_rate=0.5)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/kmong/emotion_detect/model_1.h5'))\n","model.eval()"],"metadata":{"id":"zCgcMDA1CtLy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663938726476,"user_tz":-480,"elapsed":976,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"outputId":"d40ec51d-fb70-4c13-b491-fce9c84d7fa4"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BERTClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["def predict(predict_sentence):\n","  \n","  data = [predict_sentence, '0']\n","  dataset_another = [data]\n","\n","  another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n","  test_dataloader = torch.utils.data.DataLoader(another_test, batch_size = batch_size, num_workers=5)\n","\n","  model.eval()\n","\n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","    token_ids = token_ids.long()\n","    segment_ids = segment_ids.long()\n","\n","    valid_length = valid_length\n","    label = label.long()\n","\n","    out = model(token_ids, valid_length, segment_ids)\n","\n","    test_eval=[]\n","\n","    for i in out:\n","      logits = i\n","      logits = logits.detach().numpy()\n","\n","      if np.argmax(logits) == 0:\n","        test_eval.append(\"분노가\")\n","      elif np.argmax(logits) == 1:\n","        test_eval.append(\"놀람이\")\n","      elif np.argmax(logits) == 2:\n","        test_eval.append(\"불안이\")\n","      elif np.argmax(logits) == 3:\n","        test_eval.append(\"행복이\")\n","      elif np.argmax(logits) == 4:\n","        test_eval.append(\"슬픔이\")\n","      elif np.argmax(logits) == 5:\n","        test_eval.append(\"당황이\")\n","   \n","\n","    print(\">> 입력하신 내용에서\" + test_eval[0] + \" 느껴집니다.\")\n","      "],"metadata":{"id":"3xRMwtC2h0rm","executionInfo":{"status":"ok","timestamp":1663938840536,"user_tz":-480,"elapsed":366,"user":{"displayName":"정승규","userId":"09485961021551940043"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["predict(\"정말 당황스럽다\")"],"metadata":{"id":"VNr_5CmEh0o_","executionInfo":{"status":"ok","timestamp":1663939061071,"user_tz":-480,"elapsed":1636,"user":{"displayName":"정승규","userId":"09485961021551940043"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"122f4169-ad6a-4473-a195-559f8cadfbba"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":[">> 입력하신 내용에서당황이 느껴집니다.\n"]}]}]}